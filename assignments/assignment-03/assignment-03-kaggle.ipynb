{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)001fa/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e704acde94846929861a20ac2c5da90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2cafa95ce1b4b45867ee94568581de9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)3bbb8001fa/README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcfc656ce4d3480e9756aa1278c282c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)bb8001fa/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15cceca0175d43f980a3d062e6979e6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18a580fee93b4b02bb3b54d15d6683fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ac30e8ed5f1445983abad703b08f762"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e1583b5042d4e0bb1a99180bcc5a631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00866177dc2c414f9fb24c643793a08e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)001fa/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd221c7aca7d4e8f946e9492fdbeac5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c24ea7fb7b424329a6ed731833f2410c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)3bbb8001fa/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b1920c7f46144cbb0a152161dccfc9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)b8001fa/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "433b2162f56e49dd88907a62f9324b08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230504_112031\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230504_112031\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22000\n",
      "Train Data Rows:    8000\n",
      "Train Data Columns: 384\n",
      "Label Column: salary_bin\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t10 unique label values:  [9.0, 4.0, 6.0, 3.0, 1.0, 0.0, 2.0, 8.0, 7.0, 5.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17420.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.29 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 384 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 384 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t384 features in original data used to generate 384 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.29 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.54s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7200, Val Rows: 800\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2088\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2125\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.255\t = Validation score   (accuracy)\n",
      "\t8.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.2825\t = Validation score   (accuracy)\n",
      "\t30.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.28\t = Validation score   (accuracy)\n",
      "\t44.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.2562\t = Validation score   (accuracy)\n",
      "\t5.38s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.255\t = Validation score   (accuracy)\n",
      "\t12.05s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.2688\t = Validation score   (accuracy)\n",
      "\t121.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.2675\t = Validation score   (accuracy)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.28\t = Validation score   (accuracy)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.28\t = Validation score   (accuracy)\n",
      "\t105.61s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.2688\t = Validation score   (accuracy)\n",
      "\t7.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.2812\t = Validation score   (accuracy)\n",
      "\t133.42s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2988\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 475.23s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230504_112031\\\")\n",
      "Evaluation: accuracy on test data: 0.2504317789291883\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.2504317789291883,\n",
      "    \"balanced_accuracy\": 0.24684796098838585,\n",
      "    \"mcc\": 0.16722763632222662\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.2504317789291883, 'balanced_accuracy': 0.24684796098838585, 'mcc': 0.16722763632222662}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('raw-data/train.csv')\n",
    "test_df = pd.read_csv('raw-data/test.csv')\n",
    "valid_df = pd.read_csv('raw-data/valid.csv')\n",
    "\n",
    "# Fill NaN value in 'requirements_and_role' column with an empty string\n",
    "train_df['requirements_and_role'].fillna('', inplace=True)\n",
    "\n",
    "# Separate labeled and unlabeled data\n",
    "labeled_train_df = train_df.iloc[:8000]\n",
    "unlabeled_train_df = train_df.iloc[8000:]\n",
    "\n",
    "# Initialize SBERT model\n",
    "sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Vectorize text data using SBERT\n",
    "X_labeled_train = sbert_model.encode(labeled_train_df['requirements_and_role'].tolist())\n",
    "X_test = sbert_model.encode(test_df['requirements_and_role'].tolist())\n",
    "X_valid = sbert_model.encode(valid_df['requirements_and_role'].tolist())\n",
    "\n",
    "# Create DataFrames for AutoGluon\n",
    "train_features = pd.DataFrame(X_labeled_train)\n",
    "valid_features = pd.DataFrame(X_valid)\n",
    "\n",
    "train_labels = labeled_train_df['salary_bin']\n",
    "valid_labels = valid_df['salary_bin']\n",
    "\n",
    "train_data = train_features.copy()\n",
    "train_data['salary_bin'] = train_labels\n",
    "\n",
    "valid_data = valid_features.copy()\n",
    "valid_data['salary_bin'] = valid_labels\n",
    "\n",
    "# Train an AutoGluon model\n",
    "predictor = TabularPredictor(label='salary_bin').fit(train_data)\n",
    "\n",
    "# Validate the model\n",
    "performance = predictor.evaluate(valid_data)\n",
    "print(performance)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_features = pd.DataFrame(X_test)\n",
    "predictions = predictor.predict(test_features)\n",
    "\n",
    "# Create a DataFrame for the submission\n",
    "submission = pd.DataFrame({'job_id': test_df['job_id'], 'salary_bin': predictions})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission.to_csv('test_predictions_auto_gluon_sbert.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:15:40.149177Z",
     "end_time": "2023-05-04T21:28:30.064939Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
