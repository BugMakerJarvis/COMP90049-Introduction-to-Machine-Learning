{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T11:48:45.130403Z",
     "end_time": "2023-05-05T11:48:46.075454Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "train_embeddings = np.load('embeddings-data/train-embeddings.npy')\n",
    "test_embeddings = np.load('embeddings-data/test-embeddings.npy')\n",
    "valid_embeddings = np.load('embeddings-data/valid-embeddings.npy')\n",
    "\n",
    "train_tfidf = np.load('tfidf-data/train-tfidf.npy')\n",
    "test_tfidf = np.load('tfidf-data/test-tfidf.npy')\n",
    "valid_tfidf = np.load('tfidf-data/valid-tfidf.npy')\n",
    "\n",
    "train_df = pd.read_csv('raw-data/train.csv')\n",
    "test_df = pd.read_csv('raw-data/test.csv')\n",
    "valid_df = pd.read_csv('raw-data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T11:48:46.078157Z",
     "end_time": "2023-05-05T11:48:46.138155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Fill NaN value in 'requirements_and_role' column with an empty string\n",
    "train_df['requirements_and_role'].fillna('', inplace=True)\n",
    "\n",
    "# Separate labeled and unlabeled data\n",
    "labeled_train_df = train_df.iloc[:8000]\n",
    "unlabeled_train_df = train_df.iloc[8000:]\n",
    "\n",
    "# Separate the features and labels\n",
    "X_labeled_train_embeddings = train_embeddings[:8000]\n",
    "X_labeled_train_tfidf = train_tfidf[:8000]\n",
    "X_unlabeled_train_embeddings = train_embeddings[8000:]\n",
    "X_unlabeled_train_tfidf = train_tfidf[8000:]\n",
    "\n",
    "X_labeled_train_combined = np.concatenate((X_labeled_train_embeddings, X_labeled_train_tfidf), axis=1)\n",
    "X_unlabeled_train_combined = np.concatenate((X_unlabeled_train_embeddings, X_unlabeled_train_tfidf), axis=1)\n",
    "\n",
    "valid_combined = np.concatenate((valid_embeddings, valid_tfidf), axis=1)\n",
    "\n",
    "y_train_salary_bin = labeled_train_df['salary_bin'].values\n",
    "y_valid_salary_bin = valid_df['salary_bin'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T11:48:46.140154Z",
     "end_time": "2023-05-05T11:48:46.153152Z"
    }
   },
   "outputs": [],
   "source": [
    "label = 'salary_bin'\n",
    "\n",
    "datasets = {\n",
    "    'combined': (\n",
    "        X_labeled_train_combined, y_train_salary_bin, valid_combined, y_valid_salary_bin, X_unlabeled_train_combined\n",
    "    ),\n",
    "    'embeddings': (\n",
    "        X_labeled_train_embeddings, y_train_salary_bin, valid_embeddings, y_valid_salary_bin,\n",
    "        X_unlabeled_train_embeddings\n",
    "    ),\n",
    "    'tfidf': (\n",
    "        X_labeled_train_tfidf, y_train_salary_bin, valid_tfidf, y_valid_salary_bin, X_unlabeled_train_tfidf\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T11:48:46.153152Z",
     "end_time": "2023-05-05T12:30:00.897226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230505_014847\\\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (8000 samples, 56.64 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230505_014847\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22000\n",
      "Train Data Rows:    8000\n",
      "Train Data Columns: 884\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t10 unique label values:  [9.0, 4.0, 6.0, 3.0, 1.0, 0.0, 2.0, 8.0, 7.0, 5.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15159.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 56.58 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 884 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 884 | ['0', '1', '2', '3', '4', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t884 features in original data used to generate 884 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 56.58 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7200, Val Rows: 800\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2312\t = Validation score   (accuracy)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2462\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.2662\t = Validation score   (accuracy)\n",
      "\t10.88s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.2712\t = Validation score   (accuracy)\n",
      "\t84.24s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.2762\t = Validation score   (accuracy)\n",
      "\t159.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.2838\t = Validation score   (accuracy)\n",
      "\t4.95s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.2537\t = Validation score   (accuracy)\n",
      "\t9.75s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.2725\t = Validation score   (accuracy)\n",
      "\t564.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.2588\t = Validation score   (accuracy)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.2738\t = Validation score   (accuracy)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.2588\t = Validation score   (accuracy)\n",
      "\t230.61s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.2875\t = Validation score   (accuracy)\n",
      "\t13.53s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.2875\t = Validation score   (accuracy)\n",
      "\t324.45s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3175\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1413.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230505_014847\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230505_021223\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230505_021223\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22000\n",
      "Train Data Rows:    8000\n",
      "Train Data Columns: 384\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t10 unique label values:  [9.0, 4.0, 6.0, 3.0, 1.0, 0.0, 2.0, 8.0, 7.0, 5.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15778.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.29 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 384 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 384 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t384 features in original data used to generate 384 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.29 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.57s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7200, Val Rows: 800\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2075\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2375\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "D:\\Melb\\2023-se1\\COMP90049-Introduction to Machine Learning\\venv\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:154: RuntimeWarning: divide by zero encountered in divide\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "D:\\Melb\\2023-se1\\COMP90049-Introduction to Machine Learning\\venv\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:154: RuntimeWarning: divide by zero encountered in divide\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "No improvement since epoch 0: early stopping\n",
      "D:\\Melb\\2023-se1\\COMP90049-Introduction to Machine Learning\\venv\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:154: RuntimeWarning: divide by zero encountered in divide\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "\t0.1\t = Validation score   (accuracy)\n",
      "\t6.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.2712\t = Validation score   (accuracy)\n",
      "\t29.95s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.275\t = Validation score   (accuracy)\n",
      "\t57.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.2712\t = Validation score   (accuracy)\n",
      "\t5.65s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.2512\t = Validation score   (accuracy)\n",
      "\t12.43s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.2862\t = Validation score   (accuracy)\n",
      "\t140.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.2662\t = Validation score   (accuracy)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.2575\t = Validation score   (accuracy)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.2662\t = Validation score   (accuracy)\n",
      "\t106.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.2662\t = Validation score   (accuracy)\n",
      "\t8.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.74375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.265\t = Validation score   (accuracy)\n",
      "\t165.97s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2975\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 540.44s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230505_021223\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230505_022125\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230505_022125\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22000\n",
      "Train Data Rows:    8000\n",
      "Train Data Columns: 500\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t10 unique label values:  [9.0, 4.0, 6.0, 3.0, 1.0, 0.0, 2.0, 8.0, 7.0, 5.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15799.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 32.0 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 500 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t500 features in original data used to generate 500 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 32.0 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.61s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7200, Val Rows: 800\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.1675\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.185\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.2312\t = Validation score   (accuracy)\n",
      "\t10.71s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.2488\t = Validation score   (accuracy)\n",
      "\t27.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.2425\t = Validation score   (accuracy)\n",
      "\t31.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.2625\t = Validation score   (accuracy)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.2512\t = Validation score   (accuracy)\n",
      "\t2.78s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.2638\t = Validation score   (accuracy)\n",
      "\t193.69s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.2688\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.2662\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.2488\t = Validation score   (accuracy)\n",
      "\t114.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.265\t = Validation score   (accuracy)\n",
      "\t12.86s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.2512\t = Validation score   (accuracy)\n",
      "\t111.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2912\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 512.65s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230505_022125\\\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Initialize dictionaries to store confident samples and predictions for each dataset\n",
    "confident_samples_dict = {}\n",
    "confident_predictions_dict = {}\n",
    "\n",
    "for data_name, (X_train, y_train, _, _, X_unlabeled) in datasets.items():\n",
    "    # Use AutoGluon to predict labels for unlabeled data\n",
    "    train_data = pd.DataFrame(X_train)\n",
    "    train_data['label'] = y_train\n",
    "\n",
    "    predictor = TabularPredictor(label='label').fit(train_data=train_data)\n",
    "\n",
    "    unlabeled_data = pd.DataFrame(X_unlabeled)\n",
    "    unlabeled_predictions = predictor.predict(unlabeled_data)\n",
    "\n",
    "    confident_samples_dict[data_name] = X_unlabeled\n",
    "    confident_predictions_dict[data_name] = unlabeled_predictions.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T12:30:00.907523Z",
     "end_time": "2023-05-05T12:52:52.089507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN on combined data\n",
      "Accuracy: 0.2141623488773748\n",
      "Precision: 0.20668085627261887\n",
      "Recall: 0.2141623488773748\n",
      "F1-score: 0.20568786889198232\n",
      "\n",
      "KNN on combined data with self-training\n",
      "Accuracy: 0.2251007484168106\n",
      "Precision: 0.209483017465995\n",
      "Recall: 0.2251007484168106\n",
      "F1-score: 0.21075614902757725\n",
      "\n",
      "Logistic Regression on combined data\n",
      "Accuracy: 0.2274035693724813\n",
      "Precision: 0.21598954604961518\n",
      "Recall: 0.2274035693724813\n",
      "F1-score: 0.21808175286307932\n",
      "\n",
      "Logistic Regression on combined data with self-training\n",
      "Accuracy: 0.23546344271732872\n",
      "Precision: 0.2194381699617523\n",
      "Recall: 0.23546344271732872\n",
      "F1-score: 0.21339612748724743\n",
      "\n",
      "SVM on combined data\n",
      "Accuracy: 0.24870466321243523\n",
      "Precision: 0.23618464970455344\n",
      "Recall: 0.24870466321243523\n",
      "F1-score: 0.2325197677033256\n",
      "\n",
      "SVM on combined data with self-training\n",
      "Accuracy: 0.25215889464594127\n",
      "Precision: 0.24022487585927163\n",
      "Recall: 0.25215889464594127\n",
      "F1-score: 0.22527018413211408\n",
      "\n",
      "Random Forest on combined data\n",
      "Accuracy: 0.2504317789291883\n",
      "Precision: 0.24030170510528553\n",
      "Recall: 0.2504317789291883\n",
      "F1-score: 0.23746774016114724\n",
      "\n",
      "Random Forest on combined data with self-training\n",
      "Accuracy: 0.25446171560161196\n",
      "Precision: 0.25593984795519364\n",
      "Recall: 0.25446171560161196\n",
      "F1-score: 0.21798255667490246\n",
      "\n",
      "KNN on embeddings data\n",
      "Accuracy: 0.21761658031088082\n",
      "Precision: 0.21266728443126934\n",
      "Recall: 0.21761658031088082\n",
      "F1-score: 0.21115313774056654\n",
      "\n",
      "KNN on embeddings data with self-training\n",
      "Accuracy: 0.23661485319516407\n",
      "Precision: 0.22547858068042592\n",
      "Recall: 0.23661485319516407\n",
      "F1-score: 0.22074938671575062\n",
      "\n",
      "Logistic Regression on embeddings data\n",
      "Accuracy: 0.24352331606217617\n",
      "Precision: 0.2217378386396473\n",
      "Recall: 0.24352331606217617\n",
      "F1-score: 0.22323908067966025\n",
      "\n",
      "Logistic Regression on embeddings data with self-training\n",
      "Accuracy: 0.24006908462867013\n",
      "Precision: 0.2494109188883309\n",
      "Recall: 0.24006908462867013\n",
      "F1-score: 0.20499594850296474\n",
      "\n",
      "SVM on embeddings data\n",
      "Accuracy: 0.2538860103626943\n",
      "Precision: 0.2458091736851297\n",
      "Recall: 0.2538860103626943\n",
      "F1-score: 0.2358475272722567\n",
      "\n",
      "SVM on embeddings data with self-training\n",
      "Accuracy: 0.2429476108232585\n",
      "Precision: 0.24580033396874906\n",
      "Recall: 0.2429476108232585\n",
      "F1-score: 0.2098585315013425\n",
      "\n",
      "Random Forest on embeddings data\n",
      "Accuracy: 0.23891767415083479\n",
      "Precision: 0.23427284590591288\n",
      "Recall: 0.23891767415083479\n",
      "F1-score: 0.2241644214629087\n",
      "\n",
      "Random Forest on embeddings data with self-training\n",
      "Accuracy: 0.24467472654001152\n",
      "Precision: 0.23204805036734244\n",
      "Recall: 0.24467472654001152\n",
      "F1-score: 0.20265792550163672\n",
      "\n",
      "KNN on tfidf data\n",
      "Accuracy: 0.14680483592400692\n",
      "Precision: 0.18797218727613388\n",
      "Recall: 0.14680483592400692\n",
      "F1-score: 0.13605329108317188\n",
      "\n",
      "KNN on tfidf data with self-training\n",
      "Accuracy: 0.17501439263097293\n",
      "Precision: 0.20507829696280958\n",
      "Recall: 0.17501439263097293\n",
      "F1-score: 0.16648531986434492\n",
      "\n",
      "Logistic Regression on tfidf data\n",
      "Accuracy: 0.2181922855497985\n",
      "Precision: 0.20322898267070796\n",
      "Recall: 0.2181922855497985\n",
      "F1-score: 0.20646831463758641\n",
      "\n",
      "Logistic Regression on tfidf data with self-training\n",
      "Accuracy: 0.22452504317789293\n",
      "Precision: 0.19803401387970018\n",
      "Recall: 0.22452504317789293\n",
      "F1-score: 0.19648653350114118\n",
      "\n",
      "SVM on tfidf data\n",
      "Accuracy: 0.24352331606217617\n",
      "Precision: 0.22868717250273518\n",
      "Recall: 0.24352331606217617\n",
      "F1-score: 0.22835693157765616\n",
      "\n",
      "SVM on tfidf data with self-training\n",
      "Accuracy: 0.24467472654001152\n",
      "Precision: 0.2243436265716242\n",
      "Recall: 0.24467472654001152\n",
      "F1-score: 0.21489490899469624\n",
      "\n",
      "Random Forest on tfidf data\n",
      "Accuracy: 0.24582613701784686\n",
      "Precision: 0.22884058131756776\n",
      "Recall: 0.24582613701784686\n",
      "F1-score: 0.22752196334880842\n",
      "\n",
      "Random Forest on tfidf data with self-training\n",
      "Accuracy: 0.24985607369027057\n",
      "Precision: 0.2390155125662512\n",
      "Recall: 0.24985607369027057\n",
      "F1-score: 0.2127571588174474\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "                  Model     Dataset Use-unlabeled-data  Accuracy  Precision  \\\n0         Random Forest    combined                Yes  0.254462   0.255940   \n1                   SVM  embeddings                 No  0.253886   0.245809   \n2                   SVM    combined                Yes  0.252159   0.240225   \n3         Random Forest    combined                 No  0.250432   0.240302   \n4         Random Forest       tfidf                Yes  0.249856   0.239016   \n5                   SVM    combined                 No  0.248705   0.236185   \n6         Random Forest       tfidf                 No  0.245826   0.228841   \n7                   SVM       tfidf                Yes  0.244675   0.224344   \n8         Random Forest  embeddings                Yes  0.244675   0.232048   \n9                   SVM       tfidf                 No  0.243523   0.228687   \n10  Logistic Regression  embeddings                 No  0.243523   0.221738   \n11                  SVM  embeddings                Yes  0.242948   0.245800   \n12  Logistic Regression  embeddings                Yes  0.240069   0.249411   \n13        Random Forest  embeddings                 No  0.238918   0.234273   \n14                  KNN  embeddings                Yes  0.236615   0.225479   \n15  Logistic Regression    combined                Yes  0.235463   0.219438   \n16  Logistic Regression    combined                 No  0.227404   0.215990   \n17                  KNN    combined                Yes  0.225101   0.209483   \n18  Logistic Regression       tfidf                Yes  0.224525   0.198034   \n19  Logistic Regression       tfidf                 No  0.218192   0.203229   \n20                  KNN  embeddings                 No  0.217617   0.212667   \n21                  KNN    combined                 No  0.214162   0.206681   \n22                  KNN       tfidf                Yes  0.175014   0.205078   \n23                  KNN       tfidf                 No  0.146805   0.187972   \n\n      Recall  F1-score  \n0   0.254462  0.217983  \n1   0.253886  0.235848  \n2   0.252159  0.225270  \n3   0.250432  0.237468  \n4   0.249856  0.212757  \n5   0.248705  0.232520  \n6   0.245826  0.227522  \n7   0.244675  0.214895  \n8   0.244675  0.202658  \n9   0.243523  0.228357  \n10  0.243523  0.223239  \n11  0.242948  0.209859  \n12  0.240069  0.204996  \n13  0.238918  0.224164  \n14  0.236615  0.220749  \n15  0.235463  0.213396  \n16  0.227404  0.218082  \n17  0.225101  0.210756  \n18  0.224525  0.196487  \n19  0.218192  0.206468  \n20  0.217617  0.211153  \n21  0.214162  0.205688  \n22  0.175014  0.166485  \n23  0.146805  0.136053  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Dataset</th>\n      <th>Use-unlabeled-data</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Random Forest</td>\n      <td>combined</td>\n      <td>Yes</td>\n      <td>0.254462</td>\n      <td>0.255940</td>\n      <td>0.254462</td>\n      <td>0.217983</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVM</td>\n      <td>embeddings</td>\n      <td>No</td>\n      <td>0.253886</td>\n      <td>0.245809</td>\n      <td>0.253886</td>\n      <td>0.235848</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVM</td>\n      <td>combined</td>\n      <td>Yes</td>\n      <td>0.252159</td>\n      <td>0.240225</td>\n      <td>0.252159</td>\n      <td>0.225270</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Random Forest</td>\n      <td>combined</td>\n      <td>No</td>\n      <td>0.250432</td>\n      <td>0.240302</td>\n      <td>0.250432</td>\n      <td>0.237468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random Forest</td>\n      <td>tfidf</td>\n      <td>Yes</td>\n      <td>0.249856</td>\n      <td>0.239016</td>\n      <td>0.249856</td>\n      <td>0.212757</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SVM</td>\n      <td>combined</td>\n      <td>No</td>\n      <td>0.248705</td>\n      <td>0.236185</td>\n      <td>0.248705</td>\n      <td>0.232520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Random Forest</td>\n      <td>tfidf</td>\n      <td>No</td>\n      <td>0.245826</td>\n      <td>0.228841</td>\n      <td>0.245826</td>\n      <td>0.227522</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SVM</td>\n      <td>tfidf</td>\n      <td>Yes</td>\n      <td>0.244675</td>\n      <td>0.224344</td>\n      <td>0.244675</td>\n      <td>0.214895</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Random Forest</td>\n      <td>embeddings</td>\n      <td>Yes</td>\n      <td>0.244675</td>\n      <td>0.232048</td>\n      <td>0.244675</td>\n      <td>0.202658</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>tfidf</td>\n      <td>No</td>\n      <td>0.243523</td>\n      <td>0.228687</td>\n      <td>0.243523</td>\n      <td>0.228357</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Logistic Regression</td>\n      <td>embeddings</td>\n      <td>No</td>\n      <td>0.243523</td>\n      <td>0.221738</td>\n      <td>0.243523</td>\n      <td>0.223239</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>SVM</td>\n      <td>embeddings</td>\n      <td>Yes</td>\n      <td>0.242948</td>\n      <td>0.245800</td>\n      <td>0.242948</td>\n      <td>0.209859</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Logistic Regression</td>\n      <td>embeddings</td>\n      <td>Yes</td>\n      <td>0.240069</td>\n      <td>0.249411</td>\n      <td>0.240069</td>\n      <td>0.204996</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random Forest</td>\n      <td>embeddings</td>\n      <td>No</td>\n      <td>0.238918</td>\n      <td>0.234273</td>\n      <td>0.238918</td>\n      <td>0.224164</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>KNN</td>\n      <td>embeddings</td>\n      <td>Yes</td>\n      <td>0.236615</td>\n      <td>0.225479</td>\n      <td>0.236615</td>\n      <td>0.220749</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Logistic Regression</td>\n      <td>combined</td>\n      <td>Yes</td>\n      <td>0.235463</td>\n      <td>0.219438</td>\n      <td>0.235463</td>\n      <td>0.213396</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Logistic Regression</td>\n      <td>combined</td>\n      <td>No</td>\n      <td>0.227404</td>\n      <td>0.215990</td>\n      <td>0.227404</td>\n      <td>0.218082</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>KNN</td>\n      <td>combined</td>\n      <td>Yes</td>\n      <td>0.225101</td>\n      <td>0.209483</td>\n      <td>0.225101</td>\n      <td>0.210756</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Logistic Regression</td>\n      <td>tfidf</td>\n      <td>Yes</td>\n      <td>0.224525</td>\n      <td>0.198034</td>\n      <td>0.224525</td>\n      <td>0.196487</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Logistic Regression</td>\n      <td>tfidf</td>\n      <td>No</td>\n      <td>0.218192</td>\n      <td>0.203229</td>\n      <td>0.218192</td>\n      <td>0.206468</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>KNN</td>\n      <td>embeddings</td>\n      <td>No</td>\n      <td>0.217617</td>\n      <td>0.212667</td>\n      <td>0.217617</td>\n      <td>0.211153</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>KNN</td>\n      <td>combined</td>\n      <td>No</td>\n      <td>0.214162</td>\n      <td>0.206681</td>\n      <td>0.214162</td>\n      <td>0.205688</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>KNN</td>\n      <td>tfidf</td>\n      <td>Yes</td>\n      <td>0.175014</td>\n      <td>0.205078</td>\n      <td>0.175014</td>\n      <td>0.166485</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>KNN</td>\n      <td>tfidf</td>\n      <td>No</td>\n      <td>0.146805</td>\n      <td>0.187972</td>\n      <td>0.146805</td>\n      <td>0.136053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_unlabeled=None, use_unlabeled_data=False, dataset_name=None):\n",
    "    if use_unlabeled_data and X_unlabeled is not None and dataset_name is not None:\n",
    "        # Combine the labeled and predicted unlabeled data\n",
    "        X_train = np.concatenate((X_train, confident_samples_dict[dataset_name]), axis=0)\n",
    "        y_train = np.concatenate((y_train, confident_predictions_dict[dataset_name]), axis=0)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "results = []\n",
    "\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, multi_class='auto'),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Random Forest': RandomForestClassifier(criterion='gini')\n",
    "}\n",
    "\n",
    "for data_name, (X_train, y_train, X_valid, y_valid, X_unlabeled) in datasets.items():\n",
    "    for model_name, model in models.items():\n",
    "        # Train and evaluate the model without self-training\n",
    "        model = train_model(model, X_train, y_train)\n",
    "\n",
    "        # Calculate the performance metrics\n",
    "        predictions = model.predict(X_valid)\n",
    "        valid_accuracy = accuracy_score(y_valid, predictions)\n",
    "        valid_precision = precision_score(y_valid, predictions, average='weighted')\n",
    "        valid_recall = recall_score(y_valid, predictions, average='weighted')\n",
    "        valid_f1_score = f1_score(y_valid, predictions, average='weighted')\n",
    "\n",
    "        print(f'{model_name} on {data_name} data')\n",
    "        print(f'Accuracy: {valid_accuracy}')\n",
    "        print(f'Precision: {valid_precision}')\n",
    "        print(f'Recall: {valid_recall}')\n",
    "        print(f'F1-score: {valid_f1_score}')\n",
    "        print()\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Dataset': data_name,\n",
    "            'Use-unlabeled-data': 'No',\n",
    "            'Accuracy': valid_accuracy,\n",
    "            'Precision': valid_precision,\n",
    "            'Recall': valid_recall,\n",
    "            'F1-score': valid_f1_score\n",
    "        })\n",
    "\n",
    "        # Train and evaluate the model with self-training\n",
    "        model_with_unlabeled = train_model(model, X_train, y_train, X_unlabeled, use_unlabeled_data=True, dataset_name=data_name)\n",
    "\n",
    "        # Calculate the performance metrics\n",
    "        predictions_self_trained = model_with_unlabeled.predict(X_valid)\n",
    "        valid_accuracy_self_trained = accuracy_score(y_valid, predictions_self_trained)\n",
    "        valid_precision_self_trained = precision_score(y_valid, predictions_self_trained, average='weighted')\n",
    "        valid_recall_self_trained = recall_score(y_valid, predictions_self_trained, average='weighted')\n",
    "        valid_f1_score_self_trained = f1_score(y_valid, predictions_self_trained, average='weighted')\n",
    "\n",
    "        print(f'{model_name} on {data_name} data with self-training')\n",
    "        print(f'Accuracy: {valid_accuracy_self_trained}')\n",
    "        print(f'Precision: {valid_precision_self_trained}')\n",
    "        print(f'Recall: {valid_recall_self_trained}')\n",
    "        print(f'F1-score: {valid_f1_score_self_trained}')\n",
    "        print()\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Dataset': data_name,\n",
    "            'Use-unlabeled-data': 'Yes',\n",
    "            'Accuracy': valid_accuracy_self_trained,\n",
    "            'Precision': valid_precision_self_trained,\n",
    "            'Recall': valid_recall_self_trained,\n",
    "            'F1-score': valid_f1_score_self_trained\n",
    "        })\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results DataFrame in descending order of Accuracy in a table\n",
    "results_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-05T12:52:52.081212Z",
     "end_time": "2023-05-05T13:14:29.205072Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230505_025252\\\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (8000 samples, 56.64 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230505_025252\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22000\n",
      "Train Data Rows:    8000\n",
      "Train Data Columns: 884\n",
      "Label Column: salary_bin\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t10 unique label values:  [9.0, 4.0, 6.0, 3.0, 1.0, 0.0, 2.0, 8.0, 7.0, 5.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16240.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 56.58 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 884 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 884 | ['0', '1', '2', '3', '4', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t884 features in original data used to generate 884 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 56.58 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7200, Val Rows: 800\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2312\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2462\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.2662\t = Validation score   (accuracy)\n",
      "\t10.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.2712\t = Validation score   (accuracy)\n",
      "\t79.71s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.2762\t = Validation score   (accuracy)\n",
      "\t135.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.2838\t = Validation score   (accuracy)\n",
      "\t4.85s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.2537\t = Validation score   (accuracy)\n",
      "\t9.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.2725\t = Validation score   (accuracy)\n",
      "\t536.85s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.2588\t = Validation score   (accuracy)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.2738\t = Validation score   (accuracy)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.2588\t = Validation score   (accuracy)\n",
      "\t202.39s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.2875\t = Validation score   (accuracy)\n",
      "\t12.39s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.2875\t = Validation score   (accuracy)\n",
      "\t294.63s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3175\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1295.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230505_025252\\\")\n"
     ]
    }
   ],
   "source": [
    "# AutoGluon - Without self-training\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Use the combined labeled training data (embeddings and TF-IDF)\n",
    "X_train = X_labeled_train_combined\n",
    "train_data = pd.DataFrame(X_train)\n",
    "train_data[label] = y_train_salary_bin\n",
    "\n",
    "# Use the combined test data (embeddings and TF-IDF)\n",
    "X_test = np.concatenate((test_embeddings, test_tfidf), axis=1)\n",
    "test_data = pd.DataFrame(X_test)\n",
    "\n",
    "predictor = TabularPredictor(label=label).fit(train_data=train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'job_id': test_df['job_id'], label: predictions})\n",
    "\n",
    "submission.to_csv('test_predictions_auto_gluon.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
